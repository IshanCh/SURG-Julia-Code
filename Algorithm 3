using LinearAlgebra # Operations
using Random # Random Number Generator
using Graphs # Network Structure
using GLMakie # Visualization & Plotting

# Function to convert a graph to a simple directed full-digraph (reuse from Algorithm 1)
function graph_to_digraph(G)
    N = nv(G) # Nodes in G
    g = SimpleDiGraph(N) # New Directed Graph w/ N Nodes
    for e in edges(G) # Iterates over each Edge E in Graph G
        i = src(e) # Retrieves Source Node
        j = dst(e) # Retrieves Destination Node
        add_edge!(g, i, j) # Adds the directed edge i -> j to the new graph g
        add_edge!(g, j, i) # Same for directed edge j -> i
    end
    return g
end

# Function to generate list of matrices A and b for each node
function generate_data(N, seed=2)
    Random.seed!(seed) # Reproducibility
    A_list = [] # List to store matrices A for each node
    b_list = [] # List to store vectors b for each node
    colA = rand(4:10) # Number of columns between 4 and 10
    
    for i in 1:N
        rowA = rand(11:20) # Random number of rows between 11 and 20 for each node
        A_i = hcat(ones(rowA), rand(rowA, colA - 1)) # Create matrix A_i with rowA rows and colA columns
        b_i = rand(rowA) # Create vector b_i with rowA elements
        push!(A_list, A_i) # Add A_i to the list
        push!(b_list, b_i) # Add b_i to the list
    end
    
    global_A = reduce(vcat, A_list) # Concatenate all A matrices vertically
    global_b = reduce(vcat, b_list) # Concatenate all b vectors vertically
    global_x = global_A \ global_b # Calculate the global solution global_x
    
    return A_list, b_list, global_x, colA
end

# Function to calculate the minimum eigenvalue vector for each node (this is actually sigma)
function calculate_sigma(A_list)
    return [minimum(eigvals(A' * A)) for A in A_list]
end

# Function to calculate weights w_ij based on sigma values
function calculate_weights(G, sigma)
    w = zeros(Float64, nv(G), nv(G)) # Initialize the weight matrix
    for e in edges(G)
        i = src(e)
        j = dst(e)
        w[i, j] = w[j, i] = min(sigma[i], sigma[j]) / (degree(G, i) + degree(G, j))
    end
    return w
end

# Function to check condition number and apply regularization if necessary
function condition_number_check(A)
    cond_num = cond(A' * A)
    if cond_num > 1e5
        println("High condition number detected: $cond_num, applying regularization.")
        return A' * A + 0.01 * I(size(A, 2))  # Increased regularization
    else
        return A' * A
    end
end

# Node-based distributed ADMM function
function node_based_admm(G, k, gamma, κ, A_list, b_list, global_x, colA, sigma, seed=2)
    N = nv(G) # Nodes in G
    g = graph_to_digraph(G)
    x = zeros(colA, N, k + 1) # 3D Matrix x with colA columns, N rows, and k+1 depth
    
    # Initialize with very small random values
    λ = 0.001 * randn(colA, N, k + 1) # 3D Matrix λ with very small random initialization
    θ = 0.001 * randn(colA, N, k + 1) # 3D Matrix θ with very small random initialization
    ξ = 0.001 * randn(colA, N, k + 1) # 3D Matrix ξ with very small random initialization
    
    w = calculate_weights(G, sigma) # Calculate weights w_ij based on sigma values
    
    # Define r based on the degree of each node, increased regularization
    r = [degree(G, i) for i in 1:N]
    
    threshold_crossed = false # Flag to check if the threshold has been crossed
    errors = [] # Array to store error values
    
    for iteration in 1:k # Main loop to iterate the ADMM algorithm for a specified number of iterations
        for i in 1:N # Iterate over each node
            A_i = A_list[i]  # Extract matrix A_i for node i
            b_i = b_list[i]  # Extract vector b_i for node i
            
            # Equation 56: Compute u_i^k
            u_i = θ[:, i, iteration] # + κ * ξ[:, i, iteration]
            
            # Equation 57: Compute λ_i^k, incorporating received u_j from in-neighbors
            λ[:, i, iteration + 1] = ξ[:, i, iteration]
            for j in inneighbors(g, i)
                u_j = θ[:, j, iteration] # + κ * ξ[:, j, iteration] # Calculate u_j for each in-neighbor
                λ[:, i, iteration + 1] -= w[j, i] * (u_i - u_j)
            end
            
            # Equation 51: Update x_i^k
            # x_i_next = (condition_number_check(A_i) + r[i] * I(colA)) \ (A_i' * b_i + λ[:, i, iteration + 1])  # Matrix-vector multiplication
            x_i_next = (A_i' * A_i + r[i] * I(colA)) \ (A_i' * b_i .+ λ[:, i, iteration]) # Update x
            x[:, i, iteration + 1] .= x_i_next
            
            # Debugging output for key variables
            # if iteration % 5 == 0
            #     println("Iteration $iteration: max_x = $(maximum(x_i_next)), min_x = $(minimum(x_i_next))")
            # end
            
            # Equation 58: Update θ_i^(k+1)
            θ[:, i, iteration + 1] = θ[:, i, iteration] + x_i_next
            
            # Equation 59: Update ξ_i^(k+1)
            # ξ[:, i, iteration + 1] = ξ[:, i, iteration] + λ[:, i, iteration + 1] .* x_i_next  # Element-wise multiplication
            ξ[:, i, iteration + 1] = r[i] .* x_i_next
        end
        
        max_error = maximum(norm.(x[:, :, iteration + 1] .- global_x, 2)) # Calculate the maximum error at this iteration
        push!(errors, max_error)

        if iteration % 100 == 0
            println("Iteration $iteration, max error: $max_error")
        end
        
        if isnan(max_error) || isinf(max_error)
            println("Algorithm diverged at iteration $iteration")
            break
        end

        if max_error <= 3.000000000000000e-5 && !threshold_crossed
            println("Iteration when max_error <= 3.000000000000000e-5: $iteration")
            println("-----------------------------------------------------------------------------------------Break")
            threshold_crossed = true
        end
    end
    
    println("Node-based ADMM algorithm completed.")
    return x, global_x, θ, λ, ξ, errors
end

# Main execution
N = 100 # Nodes
k = 10000 # Iterations
gamma = 0.0001 # Very small gain parameter gamma
κ = 0.0001 # Very small gain parameter kappa

# Generate data
A_list, b_list, global_x, colA = generate_data(N)
sigma = calculate_sigma(A_list) # Compute sigma values

Random.seed!(123) 
# G = erdos_renyi(N, 0.8)
# G, positions = euclidean_graph(N, 2, cutoff = .9)
G = barabasi_albert(N, 80, is_directed=false, complete=true)
is_connected(G) || println("Warning: graph is not connected")
x_values, global_x, θ_values, λ_values, ξ_values, errors = node_based_admm(G, k, gamma, κ, A_list, b_list, global_x, colA, sigma)

# Print the final solutions
println("Final solutions (x values):")
for i in 1:N
    println("Node $i: ", x_values[:, i, end])
end

# Plot the errors on a log scale using GLMakie
final_iteration = length(errors)  # Use the actual number of iterations completed
fig = Figure(size = (300, 150)) # Use size instead of resolution
ax = Axis(fig[1, 1], xlabel = "Iterations", ylabel = "Log(Error)", title = "Error Decrease Over Iterations")
lines!(ax, 1:final_iteration, log.(errors[1:final_iteration]))
display(fig)
readline()
